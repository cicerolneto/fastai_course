{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "import vgg16\n",
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function\n",
    "from keras.layers import TimeDistributed, Activation\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read()#.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600901\n",
      "PREFACE\n",
      "\n",
      "\n",
      "SUPPOSING that Truth is a woman--what then? Is there not ground\n",
      "for suspecting that all ph\n"
     ]
    }
   ],
   "source": [
    "print(len(text))\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are thinkers who believe in the saints.\r\n",
      "\r\n",
      "\r\n",
      "144\r\n",
      "\r\n",
      "It stands to reason that this sketch of the saint, made upon the model\r\n",
      "of the whole species, can be confronted with many opposing sketches that\r\n",
      "would create a more agreeable impression. There are certain exceptions\r\n",
      "among the species who distinguish themselves either by especial\r\n",
      "gentleness or especial humanity, and perhaps by the strength of their\r\n",
      "own personality. Others are in the highest degree fascinating because\r\n",
      "certain of their delusions shed a particular glow over their whole\r\n",
      "being, as is the case with the founder of christianity who took himself\r\n",
      "for the only begotten son of God and hence felt himself sinless; so that\r\n",
      "through his imagination--that should not be too harshly judged since the\r\n",
      "whole of antiquity swarmed with sons of god--he attained the same goal,\r\n",
      "the sense of complete sinlessness, complete irresponsibility, that can\r\n",
      "now be attained by every individual through science.--In the same manner\r\n",
      "I have viewed the saints of India who occupy an intermediate station\r\n",
      "between the christian saints and the Greek philosophers and hence are\r\n",
      "not to be regarded as a pure type. Knowledge and science--as far as they\r\n",
      "existed--and superiority to the rest of mankind by logical discipline\r\n",
      "and training of the intellectual powers were insisted upon by the\r\n",
      "Buddhists as essential to sanctity, just as they were denounced by the\r\n",
      "christian world as the indications of sinfulness."
     ]
    }
   ],
   "source": [
    "!tail -n25 {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x00', '\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x86', '\\xa4', '\\xa6', '\\xa9', '\\xab', '\\xc3']\n",
      "86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\x00\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz\\x86\\xa4\\xa6\\xa9\\xab\\xc3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "chars.insert(0, '\\0') # Make the index starting from 1\n",
    "print(chars)\n",
    "print(len(chars))\n",
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_to_index = {c:i for i, c in enumerate(chars)}\n",
    "index_to_char = {i:c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexes = [char_to_index[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what th'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([index_to_char[i] for i in indexes[:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 40\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(len(indexes)- max_len):\n",
    "    sentences.append(indexes[i:i+max_len])\n",
    "    next_chars.append(indexes[i+1:i+max_len+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600861\n",
      "600861\n",
      "[41, 2, 50, 42, 45, 39, 31, 2, 28, 46, 2, 47, 35, 32, 2, 36, 41, 31, 36, 30, 28, 47, 36, 42, 41, 46, 2, 42, 33, 2, 46, 36, 41, 33, 48, 39, 41, 32, 46, 46]\n",
      "[2, 50, 42, 45, 39, 31, 2, 28, 46, 2, 47, 35, 32, 2, 36, 41, 31, 36, 30, 28, 47, 36, 42, 41, 46, 2, 42, 33, 2, 46, 36, 41, 33, 48, 39, 41, 32, 46, 46, 10]\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))\n",
    "print(len(next_chars))\n",
    "#print(text[:50])\n",
    "print(\"%s\\n%s\"%(sentences[-1], next_chars[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600861, 40)\n",
      "(600861, 40)\n"
     ]
    }
   ],
   "source": [
    "#[np.array(s) for s in sentences]\n",
    "#m = np.concatenate([np.array([s for s in ss]) for ss in sentences])\n",
    "sentences1 = np.row_stack([[s for s in ss] for ss in sentences])\n",
    "next_chars1 = np.row_stack([[s for s in ss] for ss in next_chars])\n",
    "print(sentences1.shape)\n",
    "print(next_chars1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600859, 40)\n",
      "(600859, 40)\n"
     ]
    }
   ],
   "source": [
    "print(sentences.shape)\n",
    "print(next_chars.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43, 45, 32, 33, 28, 30, 32,  1,  1,  1, 46, 48, 43, 43, 42, 46, 36, 41, 34,  2, 47, 35, 28,\n",
       "       47,  2, 47, 45, 48, 47, 35,  2, 36, 46,  2, 28,  2, 50, 42, 40, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600859, 40)\n"
     ]
    }
   ],
   "source": [
    "print(next_chars.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['p', 'r', 'e', 'f', 'a', 'c', 'e', '\\n', '\\n', '\\n', 's', 'u', 'p', 'p', 'o', 's', 'i', 'n',\n",
       "       'g', ' ', 't', 'h', 'a', 't', ' ', 't', 'r', 'u', 't', 'h', ' ', 'i', 's', ' ', 'a', ' ',\n",
       "       'w', 'o', 'm', 'a'],\n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "n_fac = 24\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_example():\n",
    "    seed_string=\"ethics is a basic foundation of all that\"\n",
    "    for i in range(320):\n",
    "        x=np.array([char_to_index[c] for c in seed_string[-40:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(chars, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    print(seed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(512, recurrent_dropout=0.2, implementation=2, dropout=0.2, input_shape=(None, 24), return_sequences=True)`\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(512, recurrent_dropout=0.2, implementation=2, dropout=0.2, return_sequences=True)`\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=max_len),\n",
    "        LSTM(512, input_dim=n_fac,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        LSTM(512, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600861/600861 [==============================] - 2618s 4ms/step - loss: 1.4950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86795f3a50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences1, np.expand_dims(next_chars1,-1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that is seldom fundamental tendency than complex to the free soul, in the metaphysicians, and\n",
      "here and should aver to exist and as. finally, granting to\n",
      "which i had not shall be the most delicate and\n",
      "melanchology of will.--\"inspires his \"one widen\" feels him (are something highly\n",
      "believed in everything problem of man. a\n",
      "wi\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3-Char Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cs = 3\n",
    "c1_dat = [indexes[i] for i in range(0, len(indexes)-cs-1, cs)]\n",
    "c2_dat = [indexes[i+1] for i in range(0, len(indexes)-cs-1, cs)]\n",
    "c3_dat = [indexes[i+2] for i in range(0, len(indexes)-cs-1, cs)]\n",
    "c4_dat = [indexes[i+3] for i in range(0, len(indexes)-cs-1, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200299 200299 200299 200299\n",
      "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]\n",
      "[40, 30, 29, 1, 40, 43, 31, 61, 2, 74]\n",
      "[42, 25, 1, 43, 40, 33, 2, 54, 44, 73]\n",
      "[29, 27, 1, 45, 39, 38, 73, 73, 71, 61]\n",
      "[30, 29, 1, 40, 43, 31, 61, 2, 74, 2]\n"
     ]
    }
   ],
   "source": [
    "#c1_dat = [indexes[i] for i in xrange(0, len(indexes)-1-cs, cs)]\n",
    "print(len(c1_dat), len(c2_dat), len(c3_dat), len(c4_dat))\n",
    "print(indexes[:10])\n",
    "print(c1_dat[0:10])\n",
    "print(c2_dat[0:10])\n",
    "print(c3_dat[0:10])\n",
    "print(c4_dat[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat)\n",
    "x2 = np.stack(c2_dat)\n",
    "x3 = np.stack(c3_dat)\n",
    "y = np.stack(c4_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200299,)\n",
      "(200299,)\n",
      "(200299,)\n",
      "(200299,)\n",
      "[40 30 29  1 40]\n"
     ]
    }
   ],
   "source": [
    "print(x1.shape)\n",
    "print(x2.shape)\n",
    "print(x3.shape)\n",
    "print(y.shape)\n",
    "print(x1[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40, 30, 29,  1]),\n",
       " array([42, 25,  1, 43]),\n",
       " array([29, 27,  1, 45]),\n",
       " array([30, 29,  1, 40]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4], y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1,), dtype='int64', name = name)\n",
    "    emb = Embedding(n_in, n_out, input_length=1)(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1_in, c1 = embedding_input('c1', vocab_size, n_fac)\n",
    "c2_in, c2 = embedding_input('c2', vocab_size, n_fac)\n",
    "c3_in, c3 = embedding_input('c3', vocab_size, n_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:8: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 256\n",
    "dense_in = Dense(n_hidden, activation='relu')\n",
    "dense_hidden = Dense(n_hidden, activation='tanh')\n",
    "\n",
    "c1_hidden = dense_in(c1)\n",
    "hidden_2 = dense_hidden(c1_hidden)\n",
    "c2_dense = dense_in(c2)\n",
    "c2_hidden = merge([c2_dense, hidden_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "c3_dense = dense_in(c3)\n",
    "hidden_3 = dense_hidden(c2_hidden)\n",
    "c3_hidden=merge([c3_dense, hidden_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_out = Dense(vocab_size, activation='softmax')\n",
    "c4_out = dense_out(c3_hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model([c1_in, c2_in, c3_in], c4_out)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200299/200299 [==============================] - 12s 60us/step - loss: 2.4000\n",
      "Epoch 2/4\n",
      "200299/200299 [==============================] - 12s 60us/step - loss: 2.2638\n",
      "Epoch 3/4\n",
      "200299/200299 [==============================] - 12s 61us/step - loss: 2.2145\n",
      "Epoch 4/4\n",
      "200299/200299 [==============================] - 12s 60us/step - loss: 2.1711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0686722ad0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, nb_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "c3 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c2 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c1 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 24)        2064        c3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 24)        2064        c2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 24)        2064        c1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 24)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 24)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 24)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          6400        flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense_3[0][0]                    \n",
      "                                                                 merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 256)          0           dense_3[1][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Merge)                 (None, 256)          0           dense_3[2][0]                    \n",
      "                                                                 dense_4[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 86)           22102       merge_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 100,486\n",
      "Trainable params: 100,486\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [char_to_index[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict(arrs)\n",
    "    i = np.argmax(p)\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('phi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('cha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 8-Char Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = 8\n",
    "c_in_dat = [[indexes[i+n] for i in range(0, len(indexes)-cs-1, cs)] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40, 1, 33, 2, 72, 67, 73, 2, 68, 57],\n",
       " [42, 1, 38, 44, 2, 9, 61, 73, 73, 1],\n",
       " [29, 43, 31, 71, 54, 9, 58, 61, 2, 59],\n",
       " [30, 45, 2, 74, 2, 76, 67, 58, 60, 68],\n",
       " [25, 40, 73, 73, 76, 61, 24, 71, 71, 71],\n",
       " [27, 40, 61, 61, 68, 54, 2, 58, 68, 2],\n",
       " [29, 39, 54, 2, 66, 73, 33, 2, 74, 72],\n",
       " [1, 43, 73, 62, 54, 2, 72, 67, 67, 74]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(c_in_dat[n]) for n in range(cs)]\n",
    "[c_in_dat[n][:10] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 33, 2, 72, 67, 73, 2, 68, 57, 72]\n"
     ]
    }
   ],
   "source": [
    "c_out_dat = [indexes[i+cs] for i in range(0, len(indexes)-cs-1, cs)]\n",
    "print(c_out_dat[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = [np.stack(c[:-2]) for c in c_in_dat]\n",
    "y = np.stack(c_out_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[(75110,), (75110,), (75110,), (75110,), (75110,), (75110,), (75110,), (75110,)]\n",
      "(75110,)\n"
     ]
    }
   ],
   "source": [
    "print(len(xs))\n",
    "print([xs[n].shape for n in range(cs)])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "n_fac = 42\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1,), dtype='int64', name = name + '_in')\n",
    "    emb = Embedding(n_in, n_out, input_length=1, name = name + '_emb')(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_ins = [embedding_input('c' + str(n), vocab_size, n_fac) for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, kernel_initializer=\"identity\", activation=\"relu\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "dense_in = Dense(n_hidden, activation = \"relu\")\n",
    "dense_hidden = Dense(n_hidden, activation = 'relu', init = \"identity\")\n",
    "dense_out = Dense(vocab_size, activation = \"softmax\") #Why do we need softmax here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'theano.tensor.var.TensorVariable'> <class 'theano.tensor.var.TensorVariable'>\n"
     ]
    }
   ],
   "source": [
    "print(type(c_ins[0][0]), type(c_ins[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = dense_in(c_ins[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = merge([c_dense, hidden])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out = dense_out(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model([c[0] for c in c_ins], c_out)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      " 1408/75110 [..............................] - ETA: 9s - loss: 1.6778"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75110/75110 [==============================] - 9s 124us/step - loss: 1.7829\n",
      "Epoch 2/12\n",
      "75110/75110 [==============================] - 9s 124us/step - loss: 1.7615\n",
      "Epoch 3/12\n",
      "75110/75110 [==============================] - 9s 124us/step - loss: 1.7434\n",
      "Epoch 4/12\n",
      "75110/75110 [==============================] - 9s 124us/step - loss: 1.7257\n",
      "Epoch 5/12\n",
      "75110/75110 [==============================] - 9s 124us/step - loss: 1.7094\n",
      "Epoch 6/12\n",
      "75110/75110 [==============================] - 9s 124us/step - loss: 1.6941\n",
      "Epoch 7/12\n",
      "75110/75110 [==============================] - 9s 124us/step - loss: 1.6786\n",
      "Epoch 8/12\n",
      "75110/75110 [==============================] - 9s 124us/step - loss: 1.6661\n",
      "Epoch 9/12\n",
      "75110/75110 [==============================] - 9s 124us/step - loss: 1.6501\n",
      "Epoch 10/12\n",
      "75110/75110 [==============================] - 9s 124us/step - loss: 1.6392\n",
      "Epoch 11/12\n",
      "75110/75110 [==============================] - 9s 124us/step - loss: 1.6301\n",
      "Epoch 12/12\n",
      "75110/75110 [==============================] - 9s 124us/step - loss: 1.6176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f066a775d90>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, y, batch_size=64, nb_epoch=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('last che')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First RNN with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(256, activation=\"relu\", recurrent_initializer=\"identity\")`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=cs),\n",
    "        SimpleRNN(n_hidden, activation='relu', inner_init='identity'),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 8, 42)             3612      \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 256)               76544     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 86)                22102     \n",
      "=================================================================\n",
      "Total params: 102,258\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75110/75110 [==============================] - 11s 146us/step - loss: 2.7727\n",
      "Epoch 2/8\n",
      "75110/75110 [==============================] - 11s 146us/step - loss: 2.2619\n",
      "Epoch 3/8\n",
      "75110/75110 [==============================] - 11s 146us/step - loss: 2.0557\n",
      "Epoch 4/8\n",
      "75110/75110 [==============================] - 11s 146us/step - loss: 1.9177\n",
      "Epoch 5/8\n",
      "75110/75110 [==============================] - 11s 145us/step - loss: 1.8160\n",
      "Epoch 6/8\n",
      "75110/75110 [==============================] - 11s 145us/step - loss: 1.7343\n",
      "Epoch 7/8\n",
      "75110/75110 [==============================] - 11s 145us/step - loss: 1.6702\n",
      "Epoch 8/8\n",
      "75110/75110 [==============================] - 11s 145us/step - loss: 1.6184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0667117690>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.concatenate(xs,axis=1), y, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_keras(inp):\n",
    "    idxs = [char_to_index[c] for c in inp]\n",
    "    arrs = np.array(idxs)[np.newaxis,:]\n",
    "    p = model.predict(arrs)[0]\n",
    "    return chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('this is ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Returning Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out_dat = [[indexes[i+n] for i in range(1, len(indexes)-cs, cs)] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = [np.array(c[:-2]) for c in c_out_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40, 1, 33, 2, 72, 67, 73, 2],\n",
       " [42, 1, 38, 44, 2, 9, 61, 73],\n",
       " [29, 43, 31, 71, 54, 9, 58, 61],\n",
       " [30, 45, 2, 74, 2, 76, 67, 58],\n",
       " [25, 40, 73, 73, 76, 61, 24, 71],\n",
       " [27, 40, 61, 61, 68, 54, 2, 58],\n",
       " [29, 39, 54, 2, 66, 73, 33, 2],\n",
       " [1, 43, 73, 62, 54, 2, 72, 67]]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c_in_dat[n][:cs] for n in range(cs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[42, 1, 38, 44, 2, 9, 61, 73],\n",
       " [29, 43, 31, 71, 54, 9, 58, 61],\n",
       " [30, 45, 2, 74, 2, 76, 67, 58],\n",
       " [25, 40, 73, 73, 76, 61, 24, 71],\n",
       " [27, 40, 61, 61, 68, 54, 2, 58],\n",
       " [29, 39, 54, 2, 66, 73, 33, 2],\n",
       " [1, 43, 73, 62, 54, 2, 72, 67],\n",
       " [1, 33, 2, 72, 67, 73, 2, 68]]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c_out_dat[n][:cs] for n in range(cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp1 = Input(shape=(n_fac,), name = 'zeros')\n",
    "hidden = dense_in(inp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "outs = []\n",
    "for i in range(cs):\n",
    "    c_dense = dense_in(c_ins[i][1])\n",
    "    hidden = dense_hidden(hidden)\n",
    "    hidden = merge([c_dense, hidden], mode='sum')\n",
    "    outs.append(dense_out(hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([inp1] + [c[0] for c in c_ins], outs)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75110, 42)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = np.tile(np.zeros(n_fac), (len(xs[0]),1))\n",
    "zeros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "75110/75110 [==============================] - 25s 328us/step - loss: 20.3479 - dense_16_loss_1: 2.6217 - dense_16_loss_2: 2.5420 - dense_16_loss_3: 2.4985 - dense_16_loss_4: 2.5365 - dense_16_loss_5: 2.5645 - dense_16_loss_6: 2.6120 - dense_16_loss_7: 2.6578 - dense_16_loss_8: 2.3148\n",
      "Epoch 2/12\n",
      "75110/75110 [==============================] - 25s 329us/step - loss: 13.6544 - dense_16_loss_1: 1.6049 - dense_16_loss_2: 1.5267 - dense_16_loss_3: 1.5098 - dense_16_loss_4: 1.5795 - dense_16_loss_5: 1.6158 - dense_16_loss_6: 1.6508 - dense_16_loss_7: 1.7438 - dense_16_loss_8: 2.4230\n",
      "Epoch 3/12\n",
      "75110/75110 [==============================] - 25s 328us/step - loss: 8.9874 - dense_16_loss_1: 0.8449 - dense_16_loss_2: 0.8359 - dense_16_loss_3: 0.8526 - dense_16_loss_4: 0.8845 - dense_16_loss_5: 0.9495 - dense_16_loss_6: 1.0340 - dense_16_loss_7: 1.1242 - dense_16_loss_8: 2.4619\n",
      "Epoch 4/12\n",
      "75110/75110 [==============================] - 25s 329us/step - loss: 6.4848 - dense_16_loss_1: 0.4682 - dense_16_loss_2: 0.4844 - dense_16_loss_3: 0.4981 - dense_16_loss_4: 0.5355 - dense_16_loss_5: 0.5990 - dense_16_loss_6: 0.6927 - dense_16_loss_7: 0.7757 - dense_16_loss_8: 2.4313\n",
      "Epoch 5/12\n",
      "75110/75110 [==============================] - 25s 329us/step - loss: 5.1850 - dense_16_loss_1: 0.3066 - dense_16_loss_2: 0.3238 - dense_16_loss_3: 0.3361 - dense_16_loss_4: 0.3613 - dense_16_loss_5: 0.4089 - dense_16_loss_6: 0.4865 - dense_16_loss_7: 0.5700 - dense_16_loss_8: 2.3918\n",
      "Epoch 6/12\n",
      "75110/75110 [==============================] - 25s 329us/step - loss: 4.4467 - dense_16_loss_1: 0.2201 - dense_16_loss_2: 0.2382 - dense_16_loss_3: 0.2503 - dense_16_loss_4: 0.2683 - dense_16_loss_5: 0.3012 - dense_16_loss_6: 0.3678 - dense_16_loss_7: 0.4391 - dense_16_loss_8: 2.3617\n",
      "Epoch 7/12\n",
      "75110/75110 [==============================] - 25s 328us/step - loss: 3.9356 - dense_16_loss_1: 0.1667 - dense_16_loss_2: 0.1828 - dense_16_loss_3: 0.1944 - dense_16_loss_4: 0.2068 - dense_16_loss_5: 0.2327 - dense_16_loss_6: 0.2865 - dense_16_loss_7: 0.3450 - dense_16_loss_8: 2.3206\n",
      "Epoch 8/12\n",
      "75110/75110 [==============================] - 25s 329us/step - loss: 3.5668 - dense_16_loss_1: 0.1320 - dense_16_loss_2: 0.1461 - dense_16_loss_3: 0.1511 - dense_16_loss_4: 0.1637 - dense_16_loss_5: 0.1836 - dense_16_loss_6: 0.2270 - dense_16_loss_7: 0.2830 - dense_16_loss_8: 2.2802\n",
      "Epoch 9/12\n",
      "75110/75110 [==============================] - 25s 327us/step - loss: 3.3278 - dense_16_loss_1: 0.1103 - dense_16_loss_2: 0.1208 - dense_16_loss_3: 0.1267 - dense_16_loss_4: 0.1352 - dense_16_loss_5: 0.1526 - dense_16_loss_6: 0.1906 - dense_16_loss_7: 0.2369 - dense_16_loss_8: 2.2546\n",
      "Epoch 10/12\n",
      "75110/75110 [==============================] - 25s 327us/step - loss: 3.1454 - dense_16_loss_1: 0.0933 - dense_16_loss_2: 0.1029 - dense_16_loss_3: 0.1065 - dense_16_loss_4: 0.1168 - dense_16_loss_5: 0.1304 - dense_16_loss_6: 0.1623 - dense_16_loss_7: 0.2024 - dense_16_loss_8: 2.2307\n",
      "Epoch 11/12\n",
      "75110/75110 [==============================] - 25s 326us/step - loss: 2.9978 - dense_16_loss_1: 0.0814 - dense_16_loss_2: 0.0894 - dense_16_loss_3: 0.0908 - dense_16_loss_4: 0.1006 - dense_16_loss_5: 0.1091 - dense_16_loss_6: 0.1404 - dense_16_loss_7: 0.1762 - dense_16_loss_8: 2.2100\n",
      "Epoch 12/12\n",
      "75110/75110 [==============================] - 25s 327us/step - loss: 2.8870 - dense_16_loss_1: 0.0684 - dense_16_loss_2: 0.0784 - dense_16_loss_3: 0.0800 - dense_16_loss_4: 0.0874 - dense_16_loss_5: 0.0982 - dense_16_loss_6: 0.1243 - dense_16_loss_7: 0.1585 - dense_16_loss_8: 2.1919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0656c65b10>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([zeros]+xs, ys, batch_size=64, nb_epoch=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts(inp):\n",
    "    idxs = [char_to_index[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict([np.zeros(n_fac)[np.newaxis,:]] + arrs)\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'i', 's', ' ', 'i', 's', ' ']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(' this is')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'p', 'a', 'r', 't', ' ', 'o', 'f']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['p', 'a', 'r', 't', ' ', 'o', 'f', ' ']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(' part of')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(256, return_sequences=True, activation=\"relu\", recurrent_initializer=\"identity\")`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 8, 42)             3612      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 8, 256)            76544     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 8, 86)             22102     \n",
      "=================================================================\n",
      "Total params: 102,258\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=cs),\n",
    "        SimpleRNN(n_hidden, return_sequences=True, activation='relu', inner_init='identity'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_rnn=np.stack(np.squeeze(xs), axis=1)\n",
    "y_rnn=np.atleast_3d(np.stack(ys, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8), (75110, 8, 1))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rnn.shape, y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75110/75110 [==============================] - 12s 164us/step - loss: 2.4288\n",
      "Epoch 2/8\n",
      "75110/75110 [==============================] - 12s 163us/step - loss: 1.9992\n",
      "Epoch 3/8\n",
      "75110/75110 [==============================] - 12s 163us/step - loss: 1.8845\n",
      "Epoch 4/8\n",
      "75110/75110 [==============================] - 12s 163us/step - loss: 1.8246\n",
      "Epoch 5/8\n",
      "75110/75110 [==============================] - 12s 163us/step - loss: 1.7861\n",
      "Epoch 6/8\n",
      "75110/75110 [==============================] - 12s 163us/step - loss: 1.7586\n",
      "Epoch 7/8\n",
      "75110/75110 [==============================] - 12s 163us/step - loss: 1.7384\n",
      "Epoch 8/8\n",
      "75110/75110 [==============================] - 12s 163us/step - loss: 1.7229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f066d136fd0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn, y_rnn, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_keras(inp):\n",
    "    idxs = [char_to_index[c] for c in inp]\n",
    "    arr = np.array(idxs)[np.newaxis,:]\n",
    "    p = model.predict(arr)[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 's', ' ', 's', 's', ' ']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras(' this is')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Sequence Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(256, return_sequences=True, activation=\"relu\", input_shape=(8, 86), recurrent_initializer=\"identity\")`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "        SimpleRNN(n_hidden, return_sequences=True, input_shape=(cs, vocab_size),\n",
    "                  activation='relu', inner_init='identity'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75110, 8, 86), (75110, 8, 86))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh_ys = [to_categorical(o, vocab_size) for o in ys]\n",
    "oh_y_rnn=np.stack(oh_ys, axis=1)\n",
    "\n",
    "oh_xs = [to_categorical(o, vocab_size) for o in xs]\n",
    "oh_x_rnn=np.stack(oh_xs, axis=1)\n",
    "\n",
    "oh_x_rnn.shape, oh_y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "75110/75110 [==============================] - 10s 139us/step - loss: 2.4482\n",
      "Epoch 2/8\n",
      "75110/75110 [==============================] - 10s 138us/step - loss: 2.0428\n",
      "Epoch 3/8\n",
      "75110/75110 [==============================] - 10s 138us/step - loss: 1.9266\n",
      "Epoch 4/8\n",
      "75110/75110 [==============================] - 10s 138us/step - loss: 1.8603\n",
      "Epoch 5/8\n",
      "75110/75110 [==============================] - 10s 137us/step - loss: 1.8171\n",
      "Epoch 6/8\n",
      "75110/75110 [==============================] - 10s 137us/step - loss: 1.7862\n",
      "Epoch 7/8\n",
      "75110/75110 [==============================] - 10s 137us/step - loss: 1.7623\n",
      "Epoch 8/8\n",
      "75110/75110 [==============================] - 10s 137us/step - loss: 1.7435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f066a806090>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(oh_x_rnn, oh_y_rnn, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_oh(inp):\n",
    "    idxs = np.array([char_to_index[c] for c in inp])\n",
    "    arr = to_categorical(idxs, vocab_size)\n",
    "    p = model.predict(arr[np.newaxis,:])[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 'n', ' ', 'a', 's', ' ']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_oh(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateful Model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=cs, batch_input_shape=(bs,8)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(n_hidden, return_sequences=True, stateful=True),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mx = len(x_rnn)//bs*bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75110, 75072)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_rnn), mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "75072/75072 [==============================] - 35s 469us/step - loss: 2.2515\n",
      "Epoch 2/4\n",
      "75072/75072 [==============================] - 35s 465us/step - loss: 1.9768\n",
      "Epoch 3/4\n",
      "75072/75072 [==============================] - 35s 465us/step - loss: 1.8961\n",
      "Epoch 4/4\n",
      "75072/75072 [==============================] - 35s 465us/step - loss: 1.8483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0610b88290>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size=bs, nb_epoch=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch in args to gemm (64,256)x(256,256)->(1,256)\nApply node that caused the error: GpuGemm{inplace}(GpuDot22.0, TensorConstant{0.20000000298}, lstm_1/variable[t-1][cuda], <CudaNdarrayType(float32, matrix)>, TensorConstant{0.20000000298})\nToposort index: 10\nInputs types: [CudaNdarrayType(float32, matrix), TensorType(float32, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(float32, scalar)]\nInputs shapes: [(1, 256), (), (64, 256), (256, 256), ()]\nInputs strides: [(0, 1), (), (256, 1), (1024, 1), ()]\nInputs values: ['not shown', array(0.20000000298023224, dtype=float32), 'not shown', 'not shown', array(0.20000000298023224, dtype=float32)]\nOutputs clients: [[GpuElemwise{Composite{(clip((i0 + i1 + i2), i3, i4) * tanh(i5))},no_inplace}(CudaNdarrayConstant{[[ 0.5]]}, GpuElemwise{mul,no_inplace}.0, GpuGemm{inplace}.0, CudaNdarrayConstant{[[ 0.]]}, CudaNdarrayConstant{[[ 1.]]}, GpuElemwise{Composite{((clip((i0 + i1 + i2), i3, i4) * i5) + (clip((i0 + i6 + i7), i3, i4) * tanh((i8 + i9))))},no_inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: forall_inplace,gpu,scan_fn}(Elemwise{Maximum}[(0, 0)].0, GpuSubtensor{int64:int64:int8}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, Elemwise{Maximum}[(0, 0)].0, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, :int64:}.0, GpuSubtensor{::, :int64:}.0, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64::}.0, GpuSubtensor{::, int64::}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{x,0}.0)\nToposort index: 101\nInputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, row), CudaNdarrayType(float32, row), CudaNdarrayType(float32, row)]\nInputs shapes: [(), (8, 1, 42), (2, 64, 256), (2, 64, 256), (), (256, 256), (42, 256), (256, 256), (42, 256), (256, 256), (42, 256), (256, 256), (42, 256), (1, 256), (1, 256), (1, 256), (1, 256)]\nInputs strides: [(), (42, 0, 1), (16384, 256, 1), (16384, 256, 1), (), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (0, 1), (0, 1), (0, 1), (0, 1)]\nInputs values: [array(8), 'not shown', 'not shown', 'not shown', array(8), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']\nOutputs clients: [[GpuSubtensor{int64}(forall_inplace,gpu,scan_fn}.0, ScalarFromTensor.0)], [GpuSubtensor{int64}(forall_inplace,gpu,scan_fn}.1, ScalarFromTensor.0)], [GpuSubtensor{int64:int64:int8}(forall_inplace,gpu,scan_fn}.2, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-e7cf9ab94e62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_nexts_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' this is'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-142-0f4b8bf6f397>\u001b[0m in \u001b[0;36mget_nexts_keras\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchar_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1783\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    987\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    988\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 989\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/ubuntu/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.12-64/scan_perform/mod.cpp:4606)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/ubuntu/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.12-64/scan_perform/mod.cpp:4490)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dimension mismatch in args to gemm (64,256)x(256,256)->(1,256)\nApply node that caused the error: GpuGemm{inplace}(GpuDot22.0, TensorConstant{0.20000000298}, lstm_1/variable[t-1][cuda], <CudaNdarrayType(float32, matrix)>, TensorConstant{0.20000000298})\nToposort index: 10\nInputs types: [CudaNdarrayType(float32, matrix), TensorType(float32, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(float32, scalar)]\nInputs shapes: [(1, 256), (), (64, 256), (256, 256), ()]\nInputs strides: [(0, 1), (), (256, 1), (1024, 1), ()]\nInputs values: ['not shown', array(0.20000000298023224, dtype=float32), 'not shown', 'not shown', array(0.20000000298023224, dtype=float32)]\nOutputs clients: [[GpuElemwise{Composite{(clip((i0 + i1 + i2), i3, i4) * tanh(i5))},no_inplace}(CudaNdarrayConstant{[[ 0.5]]}, GpuElemwise{mul,no_inplace}.0, GpuGemm{inplace}.0, CudaNdarrayConstant{[[ 0.]]}, CudaNdarrayConstant{[[ 1.]]}, GpuElemwise{Composite{((clip((i0 + i1 + i2), i3, i4) * i5) + (clip((i0 + i6 + i7), i3, i4) * tanh((i8 + i9))))},no_inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: forall_inplace,gpu,scan_fn}(Elemwise{Maximum}[(0, 0)].0, GpuSubtensor{int64:int64:int8}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, Elemwise{Maximum}[(0, 0)].0, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, :int64:}.0, GpuSubtensor{::, :int64:}.0, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64:int64:}.0, GpuSubtensor{::, int64::}.0, GpuSubtensor{::, int64::}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{x,0}.0)\nToposort index: 101\nInputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, row), CudaNdarrayType(float32, row), CudaNdarrayType(float32, row)]\nInputs shapes: [(), (8, 1, 42), (2, 64, 256), (2, 64, 256), (), (256, 256), (42, 256), (256, 256), (42, 256), (256, 256), (42, 256), (256, 256), (42, 256), (1, 256), (1, 256), (1, 256), (1, 256)]\nInputs strides: [(), (42, 0, 1), (16384, 256, 1), (16384, 256, 1), (), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (1024, 1), (0, 1), (0, 1), (0, 1), (0, 1)]\nInputs values: [array(8), 'not shown', 'not shown', 'not shown', array(8), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']\nOutputs clients: [[GpuSubtensor{int64}(forall_inplace,gpu,scan_fn}.0, ScalarFromTensor.0)], [GpuSubtensor{int64}(forall_inplace,gpu,scan_fn}.1, ScalarFromTensor.0)], [GpuSubtensor{int64:int64:int8}(forall_inplace,gpu,scan_fn}.2, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "get_nexts_keras(' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
